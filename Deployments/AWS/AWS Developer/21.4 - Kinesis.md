- Easily collect, process and analyse streaming data in real time
	- Logs, metrics, website clicks, IOT telemetry data

![[AWS_Kinesis_Data_Stream.png]]

- Retention 1 to 365 days
- Abiliiy to replay data
- Inserted data cannot be deleted (immutability)
- Data that shares the same partition goes into the same shard
- Producers:
	- AWS SDK (simple producer)
	- Kinesis Producer Library (KPL) (C++ java, batch, compression, retries)
	- Kinesis Agent (monitor log files)
- Consumers
	- Write your own: (Kinesis Client Library), AWS SDK
	- Managed: AWS Lambda, Kinesis Data Firehose, Kinesis Data Analytics

# Capacity Modes

- Provisioned
	- You choose number of shards, scaled manually or through API
	- Each shard
		- 1MB/s in (or 1000 records per second)
		- 2MB/s out (or 2000 records per second)
	- Pay per shard provisioned per hour

- On demand mode
	- No need to provision or manage capacity
	- Default capacity (4 MB/s in or 4000 records per second)
	- Scales automatically based on observed peak during last 30 days
	- Pay per stream per hour & data in/out per GB

# Data Stream Security

- Control access / authorization using IAM policies
- Encryptions in flight using HTTPS endpoints
- Encryption at rest using KMS
- You can implement client side encryption if you want
- VPC endpoints available for Kinesis to access with VPC
- CloudTrail can monitor API calls

![[AWS_Kinesis_Data_Security.png]]

# Kinesis Producers

- Data records consist of:
	- Sequence number (unique per partition-key within shard)
	- Partition key (must specify while put records into stream)
	- Data blob (up to 1MB)
- `PutRecord` API
- Use batching with PutRecords API to reduce costs and increase throughput

## Partition Keys

- If one device is used a lot or partition key is not highly distributed
	- One shard ends up with more input
	- "Hot partition"

![[AWS_Kinesis_Producer_To_Shard.png]]

## ProvisionedThroughputExceeded

- When you go over the input limit of a shard
- Solution
	- Use highly distributed partition key
	- Retries with exponential back off
	- Increase number of shards (scaling)

![[AWS_Kinesis_ProvisionedThroughputExceeded.png]]

# Kinesis Consumers

- Get data records from data streams and process them
- Consumers:
	- Lambda
	- Kinesis Data Analytics
	- Kinesis Data Firehose
	- Custom consumer:
		- Classic
		- Enhanced
	- Kinesis Client Library (KCL)
		- Simplify reading from data stream

- Shared (Classic) Fan-Out Consumer
	- Pull
		- Consumers poll data from Kinesis
	- `GetRecords()`
		- Max 5 calls/sec
		- Latency ~ 200ms
	- 2MB/sec per shard shared across all consumers
		- Returns up to 10MB (then throttles for 5 seconds) or up to 10000 records
	- Lower cost

![[AWS_Kinesis_Classic_Fan_Out.png|450]]

- Enhanced Fan-Out Consumer
	- Push
		- Multiple consuming applications for the same stream
		- Kinesis pushes data to consumers over **HTTP/2** 
	- 2 MB/sec per consumer per shard
		- Latency ~ 70ms
	- Soft limit of 5 consumer application (KCL) per data stream (default)
		- Can be increased with ticket
	- `SubscribeToShard()`
	- Higher cost

![[AWS_Kinesis_Enhanced_Fan_Out.png|450]]

# Kinesis AWS Lambda

- Read records in batches
- Configure **batch size** and **batch window**
- If error lambda retries until successful or data expires
- Process up to 10 batches per shard simultaneously

![[AWS_Kinesis_Lambda_Consumer.png|500]]

# Kinesis Client Library (KCL)

- Java library
- Helps read records from Kinesis data stream with distributed applications sharing the workload
- Progress is checkpointed in DynamoDB
	- Needs IAM access
- Can run on EC2, Elastic Beanstalk, on prem
- Records read in order at shard level

- Checkpointed progress means that if an instance goes down other instances can carry on the work from the checkpoint
- Can't have more KCL apps than shards
	- Scale using more shards

![[AWS_Kinesis_KCL_Shards.png|450]]

![[AWS_Kinesis_KCL_6_Shards.png|450]]

## Shard Splitting

- Increase stream capacity
	- 1 -> 2 MB/s
- Divide a "hot shard"
- Old shard is closed
	- Will be deleted once the data is expired
- No automatic scaling (manual)
- Can't split into more than two shards in a single operation

![[AWS_Kinesis_Shard_Splitting.png|400]]

## Shard Merging

- Decrease stream capacity to save costs
- Group two low traffic (cold shards)
- Old shards are closed and deleted once data is expired
- Can't merge more than two in a single operation

![[AWS_Kinesis_Shard_Merging.png]]


# Kinesis Data Firehose

- Take data from sources and write in to destinations
	- No code required
- Destinations
	- AWS destinations
		- Amazon S3
		- Amazon RedShift (warehousing DB, copy through S3)
		- Amazon OpenSearch
	- Third Party destinations
	- Custom HTTP Endpoint

- No admin
- Serverless
- Managed service
- Pay for data going through firehose
- Near real time
	- ~60s latency
		- Default 5 mins
	- Or minimum 1MB data at a time
		- Default buffer 5MB
- Supports custom data transform with AWS Lambda
- Can send failed or all data to a backup S3 bucket

- Data streams vs Data Firehose

![[AWS_Kinesis_Data_Stream_Vs_Firehose.png]]

# Kinesis Data Analytics

## Kinesis Data Analytics for SQL applications

- Kinesis Data Stream & Firehouse
- Can enrich by adding S3 reference data
- Fully managed
- Auto scaling
- Pay by consumption rate
- Output
	- Kinesis data stream
		- Create streams out of real time analytics queries
	- Kinesis Data Firehose
		- Send analytics query results to destinations

- Use cases
	- Time series analytics
	- Real time dashboards
	- Real time metrics

![[AWS_Kinesis_Analytics_SQL.png]]

## Kinesis Data Analytics Apache Flink

- Uses Kinesis data stream or Amazon MSK (Managed Streaming for Apache Kafka)
- Process and analyse streaming data
	- Java, Scala or SQL
- Run any Apache Flink application on a managed cluster on AWS
	- Auto scaling
	- Parallel computation
	- Use any Apache Flink features
	- **Does NOT** read from firehose

![[AWS_Kinesis_Analytics_Flink.png]]

